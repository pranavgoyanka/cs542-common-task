{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some constants\n",
    "latitude = [40.79736, 41.78701, 30.1444, 25.7738]\n",
    "longitude = [-73.97785, -87.77166, -97.66876, -80.1936]\n",
    "cities = [\"ny\", \"il\", \"tx\", \"fl\"]\n",
    "start_date = \"2016-01-01\"\n",
    "end_date = \"2024-03-17\"\n",
    "time_steps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(city, name_prefix=\"\"):\n",
    "  # Step 1: Load your data\n",
    "  # Assume 'df' is your DataFrame with columns 'date', 'day_of_year', 'tmax', 'tmin', 'precipitation', 'humidity'\n",
    "  df = pd.read_pickle(\"./Data/data_cleaned_\"+ city +\".pkl\")\n",
    "  df['date'] = pd.to_datetime(df['date'])\n",
    "  df.set_index('date', inplace=True)\n",
    "  # df.loc[datetime.datetime(2016, 1, 1), datetime.datetime(2024, 2, 29)]\n",
    "\n",
    "  df['tmax_avg'].plot(figsize=(10,6))\n",
    "  # plt.show()\n",
    "  \n",
    "  df = df.rename(columns={\"day\": \"day_of_year\", \"tmax_avg\":\"tmax\", \"tmin_avg\": \"tmin\", 'prec_om': \"prec\", 'humi_vc': \"humi\"})\n",
    "#   df.info()\n",
    "  features = ['day_of_year', 'tmax', 'tmin', 'prec', 'humi']\n",
    "  df = df[features]\n",
    "\n",
    "  df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "  target = 'tmax'\n",
    "  # Normalize the features\n",
    "  scaler = StandardScaler()\n",
    "  df_scaled = scaler.fit_transform(df[features])\n",
    "\n",
    "  # Function to create a dataset for LSTM\n",
    "  def create_dataset(X, y, time_steps=1):\n",
    "      Xs, ys = [], []\n",
    "      for i in range(len(X) - time_steps):\n",
    "          v = X[i:(i + time_steps)]\n",
    "          Xs.append(v)\n",
    "          ys.append(y[i + time_steps])\n",
    "      return np.array(Xs), np.array(ys)\n",
    "\n",
    "  # Use this many days of data to predict the next day's 'tmax'\n",
    "  X, y = create_dataset(df_scaled, df_scaled[:, 1], time_steps)\n",
    "  split = int(len(X) * 0.80) \n",
    "  \n",
    "  # Split the data\n",
    "  X_train, X_test = X[:split], X[split:]\n",
    "  y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "  # LSTM model\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(70, activation='relu', input_shape=(time_steps, X.shape[2])))\n",
    "  model.add(Dense(1))\n",
    "  model.compile(optimizer=Adam(0.001), loss='mean_squared_error')\n",
    "  model.fit(X_train, y_train, epochs=80, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "  # Evaluate the model\n",
    "  mse = model.evaluate(X_test, y_test, verbose=0)\n",
    "  print(f'Test MSE: {mse}')\n",
    "  model.save(\"./Data/\" + name_prefix + \"model_\" + city + '.keras')\n",
    "  # Predictions\n",
    "  predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrediction(city, name_prefix=\"\", offset=0):\n",
    "    model = tf.keras.models.load_model(\"./Data/\" + name_prefix + 'model_'+city+'.keras')\n",
    "    df = pd.read_pickle(\"./Data/prediction_data_cleaned_\"+ city +\".pkl\")\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df.set_index('date', inplace=True)\n",
    "    df = df.rename(columns={\"day\": \"day_of_year\", \"tmax_avg\":\"tmax\", \"tmin_avg\": \"tmin\", 'prec_om': \"prec\", 'humi_vc': \"humi\"})\n",
    "    # df.info()\n",
    "    features = ['day_of_year', 'tmax', 'tmin', 'prec', 'humi']\n",
    "    df = df[features]\n",
    "    target = 'tmax'\n",
    "\n",
    "    # Normalize the features\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = scaler.fit_transform(df[features])\n",
    "\n",
    "    # Use this many days of data to predict the next day's 'tmax'\n",
    "    # X, y = create_dataset(df_scaled, df_scaled[:, 1], time_steps)\n",
    "    # split = int(len(X) * 0.75)  # 70% for training\n",
    "\n",
    "    # # Split the data\n",
    "    # X_train, X_test = X[:split], X[split:]\n",
    "    # y_train, y_test = y[:split], y[split:]\n",
    "    old_data = df[-(time_steps):]\n",
    "    if offset != 0:\n",
    "        old_data = df[-(time_steps+offset):-offset]\n",
    "    old_data.fillna(old_data.mean(), inplace=True)\n",
    "    \n",
    "    last_days_data = np.array(old_data)\n",
    "    # print(last_days_data)\n",
    "    last_days_scaled = scaler.transform(last_days_data)\n",
    "    last_days_scaled = np.expand_dims(last_days_scaled, axis=0)\n",
    "    predicted_tmax_scaled = model.predict(last_days_scaled)\n",
    "    print(model.summary())\n",
    "    dummy_array = np.zeros((1, len(features))) \n",
    "    dummy_array[:, 1] = predicted_tmax_scaled\n",
    "    inverse_transformed_array = scaler.inverse_transform(dummy_array)\n",
    "    predicted_tmax = inverse_transformed_array[:, 1]\n",
    "\n",
    "    print(f\"Predicted 'tmax' for {city} for next day: {predicted_tmax[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in cities:\n",
    "  trainModel(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in cities:\n",
    "  getPrediction(city)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs542",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
