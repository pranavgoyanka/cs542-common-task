{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "import pandas as pd\n",
    "from retry_requests import retry\n",
    "import requests\n",
    "import pathlib\n",
    "import json\n",
    "from datetime import datetime\n",
    "from meteostat import Stations, Daily\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Load API keys\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv() \n",
    "# print(type(os.getenv(\"VISUAL_CROSSING_API_KEY\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some constants\n",
    "latitude = [40.79736, 41.78701, 30.1444, 25.7738]\n",
    "longitude = [-73.97785, -87.77166, -97.66876, -80.1936]\n",
    "cities = [\"ny\", \"il\", \"tx\", \"fl\"]\n",
    "start_date = \"2016-01-01\"\n",
    "end_date = \"2024-03-12\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Calls to collect historical weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Meteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataFromOpenMeteo(latitude, longitude, startDate, endDate, fileName):\n",
    "  # Data Source 1\n",
    "\t# Setup the Open-Meteo API client with cache and retry on error\n",
    "\tcache_session = requests_cache.CachedSession('.cache', expire_after = -1)\n",
    "\tretry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
    "\topenmeteo = openmeteo_requests.Client(session = retry_session)\n",
    "\n",
    "\t# Make sure all required weather variables are listed here\n",
    "\t# The order of variables in hourly or daily is important to assign them correctly below\n",
    "\turl = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\tparams = {\n",
    "\t\t\"latitude\": latitude,\n",
    "\t\t\"longitude\": longitude,\n",
    "\t\t\"start_date\": startDate,\n",
    "\t\t\"end_date\": endDate,\n",
    "\t\t\"daily\": [\"temperature_2m_max\", \"temperature_2m_min\", \"sunshine_duration\", \"precipitation_hours\", \"wind_speed_10m_max\"],\n",
    "\t}\n",
    "\tresponses = openmeteo.weather_api(url, params=params)\n",
    "\n",
    "\t# Process first location. Add a for-loop for multiple locations or weather models\n",
    "\tresponse = responses[0]\n",
    "\tprint(f\"Coordinates {response.Latitude()}°N {response.Longitude()}°E\")\n",
    "\tprint(f\"Elevation {response.Elevation()} m asl\")\n",
    "\tprint(f\"Timezone {response.Timezone()} {response.TimezoneAbbreviation()}\")\n",
    "\tprint(f\"Timezone difference to GMT+0 {response.UtcOffsetSeconds()} s\")\n",
    "\n",
    "\t# Process daily data. The order of variables needs to be the same as requested.\n",
    "\tdaily = response.Daily()\n",
    "\tdaily_temperature_2m_max = daily.Variables(0).ValuesAsNumpy()\n",
    "\tdaily_temperature_2m_min = daily.Variables(1).ValuesAsNumpy()\n",
    "\tdaily_sunshine_duration = daily.Variables(2).ValuesAsNumpy()\n",
    "\tdaily_precipitation_hours = daily.Variables(3).ValuesAsNumpy()\n",
    "\tdaily_wind_speed_10m_max = daily.Variables(4).ValuesAsNumpy()\n",
    "\n",
    "\tdaily_data = {\"date\": pd.date_range(\n",
    "\t\tstart = pd.to_datetime(daily.Time(), unit = \"s\", utc = True),\n",
    "\t\tend = pd.to_datetime(daily.TimeEnd(), unit = \"s\", utc = True),\n",
    "\t\tfreq = pd.Timedelta(seconds = daily.Interval()),\n",
    "\t\tinclusive = \"left\"\n",
    "\t)}\n",
    "\tdaily_data[\"temperature_2m_max\"] = daily_temperature_2m_max\n",
    "\tdaily_data[\"temperature_2m_min\"] = daily_temperature_2m_min\n",
    "\tdaily_data[\"sunshine_duration\"] = daily_sunshine_duration\n",
    "\tdaily_data[\"precipitation_hours\"] = daily_precipitation_hours\n",
    "\tdaily_data[\"wind_speed_10m_max\"] = daily_wind_speed_10m_max\n",
    "\n",
    "\tdaily_dataframe = pd.DataFrame(data = daily_data)\n",
    "\tdaily_dataframe.to_csv(\"openMeteo_\" + '_'.join([fileName, startDate, 'to', endDate]) +  \".csv\", index=False)\n",
    "\treturn daily_dataframe\n",
    "\t# print(daily_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING!!!\n",
    "# This has already been run for 2016-01-01 to 2024-03-12\n",
    "# Don't re-run and make repeated API calls unless needed\n",
    "# Get data from OpenMeteo\n",
    "\n",
    "# daily_data = []\n",
    "# for i in range(len(latitude)):\n",
    "#   daily_data.append(getDataFromOpenMeteo(latitude[i], longitude[i], start_date, end_date, cities[i]))\n",
    "\n",
    "# print(len(daily_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Crossing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataFromVisualCrossing(latitude, longitude, startDate, endDate, fileName):\n",
    "  url = \"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/\" + str (latitude) + \\\n",
    "        \"%2C\" + str(longitude) + \"/\" + startDate + \"/\" + endDate + \"?unitGroup=us&include=days&key=\"+ os.getenv(\"VISUAL_CROSSING_API_KEY\") + \"&contentType=json\"\n",
    "  print(url)\n",
    "  print(\"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/40.79736%2C-73.97785/2016-01-01/today?unitGroup=us&include=days&key=MHFU2QHX7NTY5RTWZPAT7VBXS&contentType=json\")\n",
    "# \"https://weather.visualcrossing.com/VisualCrosingWebServices/rest/services/timeline/\n",
    "# 40.79736%2C-73.97785/2016-01-01/today?unitGroup=us&include=days&key=MHFU2QHX7NTY5RTWZPAT7VBXS&contentType=json\"\n",
    "\n",
    "\n",
    "  payload={}\n",
    "  headers = {}\n",
    "\n",
    "  response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "  pathlib.Path(\"visualCrossing_\" + '_'.join([fileName, startDate, 'to', endDate]) + '.json').write_bytes(response.content)\n",
    "\n",
    "  print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING!!!\n",
    "# Will incur an API cost, don't re-run\n",
    "# Historical Data is saved to a CSV\n",
    "\n",
    "# visual_crossing_data = []\n",
    "# for i in range(len(latitude)):\n",
    "  # daily_data.append(\n",
    "  # visual_crossing_data.append(getDataFromVisualCrossing(latitude[i], longitude[i], start_date, end_date, cities[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meteostat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                            name country region   wmo  icao  latitude  \\\n",
      "id                                                                      \n",
      "KNYC0  New York City / Yorkville      US     NY  <NA>  KNYC   40.7789   \n",
      "\n",
      "       longitude  elevation          timezone hourly_start hourly_end  \\\n",
      "id                                                                      \n",
      "KNYC0   -73.9692        3.0  America/New_York   1943-12-01 2024-03-08   \n",
      "\n",
      "      daily_start  daily_end monthly_start monthly_end     distance  \n",
      "id                                                                   \n",
      "KNYC0  1943-12-02 2022-04-24    1944-01-01  2021-01-01  2178.011255  ,                          name country region    wmo  icao  latitude  \\\n",
      "id                                                                    \n",
      "72534  Chicago Midway Airport      US     IL  72534  KMDW   41.7833   \n",
      "\n",
      "       longitude  elevation         timezone hourly_start hourly_end  \\\n",
      "id                                                                     \n",
      "72534     -87.75      189.0  America/Chicago   1973-01-01 2024-03-08   \n",
      "\n",
      "      daily_start  daily_end monthly_start monthly_end     distance  \n",
      "id                                                                   \n",
      "72534  1928-02-29 2024-03-06    1928-01-01  2022-01-01  1842.654036  ,                      name country region    wmo  icao  latitude  longitude  \\\n",
      "id                                                                           \n",
      "74745  Austin / Del Valle      US     TX  74745  KAUS   30.1945   -97.6699   \n",
      "\n",
      "       elevation         timezone hourly_start hourly_end daily_start  \\\n",
      "id                                                                      \n",
      "74745      165.0  America/Chicago   1999-05-24 2024-03-08  1948-03-01   \n",
      "\n",
      "       daily_end monthly_start monthly_end     distance  \n",
      "id                                                       \n",
      "74745 2024-12-30    1949-01-01  2022-01-01  5571.943674  ,                               name country region    wmo  icao  latitude  \\\n",
      "id                                                                         \n",
      "72202  Miami International Airport      US     FL  72202  KMIA   25.7833   \n",
      "\n",
      "       longitude  elevation          timezone hourly_start hourly_end  \\\n",
      "id                                                                      \n",
      "72202   -80.3167        4.0  America/New_York   1973-01-01 2024-03-08   \n",
      "\n",
      "      daily_start  daily_end monthly_start monthly_end      distance  \n",
      "id                                                                    \n",
      "72202  1948-01-01 2024-12-30    1948-01-01  2022-01-01  12371.061174  ]\n"
     ]
    }
   ],
   "source": [
    "# Get weather stations\n",
    "stations = Stations()\n",
    "required_stations = []\n",
    "for i in range(len(latitude)):\n",
    "  stations = stations.nearby(latitude[i], longitude[i])\n",
    "  station = stations.fetch(1)\n",
    "  required_stations.append(station)\n",
    "\n",
    "# print(required_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataFromMeteostat(latitude, longitude, startDate, endDate, fileName):\n",
    "  start = datetime.strptime(startDate, '%Y-%m-%d')\n",
    "  end = datetime.strptime(endDate, '%Y-%m-%d')\n",
    "  stations = Stations()\n",
    "  stations = stations.nearby(latitude, longitude)\n",
    "  station = stations.fetch(1)\n",
    "  # Get daily data\n",
    "  data = Daily(station, start, end)\n",
    "  data = data.fetch()\n",
    "  # print(data['time'])\n",
    "  data.index.names = ['date']\n",
    "  data = data.add_suffix('_ms')\n",
    "  data.to_csv(\"meteoStat_\" + '_'.join([fileName, startDate, 'to', endDate]) +  \".csv\")\n",
    "  return data\n",
    "  # data.plot(y=['tavg', 'tmin', 'tmax'])\n",
    "  # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_ms_data = []\n",
    "for i in range(len(latitude)):\n",
    "  daily_ms_data.append(getDataFromMeteostat(latitude[i], longitude[i], start_date, end_date, cities[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data from the CSV and JSON Files creates from the API calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readStoredJSONData(fileName):\n",
    "  with open(fileName, 'r') as file:\n",
    "    # Reading from json file\n",
    "    data = json.load(file)\n",
    "  return data\n",
    "\n",
    "def readStoredCSVData(fileName):\n",
    "  df = pd.read_csv(fileName)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all visual crossing files\n",
    "vc_data = []\n",
    "for i in range(len(latitude)):\n",
    "  fileName = \"visualCrossing_\" + '_'.join([cities[i], start_date, 'to', end_date]) + '.json'\n",
    "  vc_data.append(readStoredJSONData(fileName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vc_data[0]['days'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2994 entries, 0 to 2993\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   datetime   2994 non-null   object \n",
      " 1   tempmax    2994 non-null   float64\n",
      " 2   tempmin    2994 non-null   float64\n",
      " 3   humidity   2994 non-null   float64\n",
      " 4   windspeed  2994 non-null   float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 117.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2994 entries, 0 to 2993\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   datetime   2994 non-null   object \n",
      " 1   tempmax    2994 non-null   float64\n",
      " 2   tempmin    2994 non-null   float64\n",
      " 3   humidity   2994 non-null   float64\n",
      " 4   windspeed  2994 non-null   float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 117.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2994 entries, 0 to 2993\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   datetime   2994 non-null   object \n",
      " 1   tempmax    2994 non-null   float64\n",
      " 2   tempmin    2994 non-null   float64\n",
      " 3   humidity   2994 non-null   float64\n",
      " 4   windspeed  2994 non-null   float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 117.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2994 entries, 0 to 2993\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   datetime   2994 non-null   object \n",
      " 1   tempmax    2994 non-null   float64\n",
      " 2   tempmin    2994 non-null   float64\n",
      " 3   humidity   2994 non-null   float64\n",
      " 4   windspeed  2994 non-null   float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 117.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for cityData in vc_data:\n",
    "  city_df = pd.DataFrame(cityData['days'])\n",
    "  city_df = city_df[['datetime', 'tempmax', 'tempmin', 'humidity', 'windspeed']]\n",
    "  city_df['datetime'] = city_df['datetime'].apply(lambda x : str(x))\n",
    "  print(city_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2994 entries, 0 to 2993\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   datetime   2994 non-null   object \n",
      " 1   tempmax    2994 non-null   float64\n",
      " 2   tempmin    2994 non-null   float64\n",
      " 3   humidity   2994 non-null   float64\n",
      " 4   windspeed  2994 non-null   float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 117.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2994 entries, 0 to 2993\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   datetime   2994 non-null   object \n",
      " 1   tempmax    2994 non-null   float64\n",
      " 2   tempmin    2994 non-null   float64\n",
      " 3   humidity   2994 non-null   float64\n",
      " 4   windspeed  2994 non-null   float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 117.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2994 entries, 0 to 2993\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   datetime   2994 non-null   object \n",
      " 1   tempmax    2994 non-null   float64\n",
      " 2   tempmin    2994 non-null   float64\n",
      " 3   humidity   2994 non-null   float64\n",
      " 4   windspeed  2994 non-null   float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 117.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2994 entries, 0 to 2993\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   datetime   2994 non-null   object \n",
      " 1   tempmax    2994 non-null   float64\n",
      " 2   tempmin    2994 non-null   float64\n",
      " 3   humidity   2994 non-null   float64\n",
      " 4   windspeed  2994 non-null   float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 117.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "vc_dfs = []\n",
    "for cityData in vc_data:\n",
    "  city_df = pd.DataFrame(cityData['days'])\n",
    "  city_df = city_df[['datetime', 'tempmax', 'tempmin', 'humidity', 'windspeed']]\n",
    "  print(city_df.info())\n",
    "  vc_dfs.append(city_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all open meteo files\n",
    "om_dfs = []\n",
    "for i in range(len(latitude)):\n",
    "  fileName = \"openMeteo_\" + '_'.join([cities[i], start_date, 'to', end_date]) + '.csv'\n",
    "  om_df = readStoredCSVData(fileName)\n",
    "  # print(type(om_df['date'][0]))\n",
    "  # om_df['date'] = om_df['date'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%d\"))\n",
    "  om_df['date'] = om_df['date'].apply(lambda x: x[:10])\n",
    "  om_df.set_index('date')\n",
    "  om_dfs.append(om_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2994 entries, 0 to 2993\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   date     2994 non-null   object \n",
      " 1   tmax_om  2992 non-null   float64\n",
      " 2   tmin_om  2992 non-null   float64\n",
      " 3   sund_om  2992 non-null   float64\n",
      " 4   prec_om  2994 non-null   float64\n",
      " 5   wind_om  2992 non-null   float64\n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 140.5+ KB\n"
     ]
    }
   ],
   "source": [
    "om_dfs[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_dfs = []\n",
    "for i in range(len(latitude)):\n",
    "  fileName = \"meteoStat_\" + '_'.join([cities[i], start_date, 'to', end_date]) + '.csv'\n",
    "  ms_df = readStoredCSVData(fileName)\n",
    "  ms_df['date'] = ms_df['date'].apply(lambda x: x[:10])\n",
    "  ms_df.set_index('date')\n",
    "  ms_dfs.append(ms_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  tmax_vc  tmin_vc  humi_vc  wind_vc\n",
      "0  2016-01-01     42.2     35.1     52.5     13.9\n",
      "1  2016-01-02     39.8     33.3     47.4     13.7\n",
      "2  2016-01-03     44.3     34.9     48.6     16.3\n",
      "3  2016-01-04     36.1     15.2     46.4     19.2\n",
      "4  2016-01-05     28.6     11.3     38.8     14.8\n",
      "<class 'pandas.core.series.Series'>\n",
      "         date  tmax_om  tmin_om    sund_om  prec_om    wind_om\n",
      "0  2016-01-01     6.73     1.88  27001.312      0.0  21.077686\n",
      "1  2016-01-02     4.38    -1.42  29190.664      0.0  15.856356\n",
      "2  2016-01-03     6.58    -0.97  29205.188      0.0  19.083395\n",
      "3  2016-01-04     2.08    -5.47  29141.408      0.0  24.280659\n",
      "4  2016-01-05    -1.22   -10.02  29472.777      0.0  26.282465\n",
      "         date  tavg_ms  tmin_ms  tmax_ms  prcp_ms  snow_ms  wdir_ms  wspd_ms  \\\n",
      "0  2020-01-15      7.8      6.0     10.0      NaN      NaN      NaN      NaN   \n",
      "1  2020-01-16      6.0      1.0      9.0      NaN      NaN      NaN      NaN   \n",
      "2  2020-01-17     -3.5     -6.0      1.0      NaN      NaN      NaN      NaN   \n",
      "3  2020-01-18     -3.0     -7.0      3.0      NaN      NaN      NaN      NaN   \n",
      "4  2020-01-19      3.1     -2.0      6.0      NaN      NaN      NaN      NaN   \n",
      "\n",
      "   wpgt_ms  pres_ms  tsun_ms  \n",
      "0      NaN      NaN      NaN  \n",
      "1      NaN      NaN      NaN  \n",
      "2      NaN      NaN      NaN  \n",
      "3      NaN      NaN      NaN  \n",
      "4      NaN      NaN      NaN  \n"
     ]
    }
   ],
   "source": [
    "# print(vc_dfs[0].info())\n",
    "# print(om_dfs[0].info())\n",
    "\n",
    "for vc_df in vc_dfs:\n",
    "  vc_df.columns = ['date', 'tmax_vc', 'tmin_vc', 'humi_vc', 'wind_vc']\n",
    "  vc_df.set_index('date')\n",
    "  \n",
    "for om_df in om_dfs:\n",
    "  om_df.columns = ['date', 'tmax_om', 'tmin_om', 'sund_om', 'prec_om', 'wind_om']\n",
    "  om_df.set_index('date')\n",
    "\n",
    "for ms_df in ms_dfs:\n",
    "  ms_df.set_index('date')\n",
    "\n",
    "print(vc_dfs[0].head())\n",
    "print(type(vc_dfs[0]['date']))\n",
    "print(om_dfs[0].head())\n",
    "print(ms_dfs[0].head())\n",
    "# all_dfs = vc_dfs + om_dfs\n",
    "# all_dfs = pd.concat(all_dfs)\n",
    "# print(all_dfs[0].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1447 entries, 0 to 1446\n",
      "Data columns (total 20 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   date     1447 non-null   object \n",
      " 1   tmax_vc  1447 non-null   float64\n",
      " 2   tmin_vc  1447 non-null   float64\n",
      " 3   humi_vc  1447 non-null   float64\n",
      " 4   wind_vc  1447 non-null   float64\n",
      " 5   tmax_om  1447 non-null   float64\n",
      " 6   tmin_om  1447 non-null   float64\n",
      " 7   sund_om  1447 non-null   float64\n",
      " 8   prec_om  1447 non-null   float64\n",
      " 9   wind_om  1447 non-null   float64\n",
      " 10  tavg_ms  1447 non-null   float64\n",
      " 11  tmin_ms  1447 non-null   float64\n",
      " 12  tmax_ms  1447 non-null   float64\n",
      " 13  prcp_ms  1159 non-null   float64\n",
      " 14  snow_ms  0 non-null      float64\n",
      " 15  wdir_ms  1159 non-null   float64\n",
      " 16  wspd_ms  1159 non-null   float64\n",
      " 17  wpgt_ms  0 non-null      float64\n",
      " 18  pres_ms  1159 non-null   float64\n",
      " 19  tsun_ms  0 non-null      float64\n",
      "dtypes: float64(19), object(1)\n",
      "memory usage: 226.2+ KB\n",
      "None\n",
      "         date  tmax_vc  tmin_vc  humi_vc  wind_vc   tmax_om  tmin_om  \\\n",
      "0  2020-01-15     50.2     42.1     66.4     11.7  9.292999    3.943   \n",
      "1  2020-01-16     48.2     35.0     63.7     19.0  8.693000    2.993   \n",
      "2  2020-01-17     34.1     21.8     36.0     21.1  2.643000   -5.307   \n",
      "3  2020-01-18     37.1     20.1     60.2     14.9  0.443000   -6.207   \n",
      "4  2020-01-19     42.4     30.9     62.2     14.6  6.793000    0.393   \n",
      "\n",
      "      sund_om  prec_om    wind_om  tavg_ms  tmin_ms  tmax_ms  prcp_ms  \\\n",
      "0  27334.9450      3.0  15.379206      7.8      6.0     10.0      NaN   \n",
      "1  26647.1230      8.0  36.719997      6.0      1.0      9.0      NaN   \n",
      "2  30645.2870      0.0  34.200000     -3.5     -6.0      1.0      NaN   \n",
      "3    942.9747      6.0  17.193533     -3.0     -7.0      3.0      NaN   \n",
      "4  22667.3570      7.0  25.071098      3.1     -2.0      6.0      NaN   \n",
      "\n",
      "   snow_ms  wdir_ms  wspd_ms  wpgt_ms  pres_ms  tsun_ms  \n",
      "0      NaN      NaN      NaN      NaN      NaN      NaN  \n",
      "1      NaN      NaN      NaN      NaN      NaN      NaN  \n",
      "2      NaN      NaN      NaN      NaN      NaN      NaN  \n",
      "3      NaN      NaN      NaN      NaN      NaN      NaN  \n",
      "4      NaN      NaN      NaN      NaN      NaN      NaN  \n"
     ]
    }
   ],
   "source": [
    "for vc_df in vc_dfs:\n",
    "  vc_df.columns = ['date', 'tmax_vc', 'tmin_vc', 'humi_vc', 'wind_vc']\n",
    "  vc_df.set_index('date')\n",
    "  \n",
    "for om_df in om_dfs:\n",
    "  om_df.columns = ['date', 'tmax_om', 'tmin_om', 'sund_om', 'prec_om', 'wind_om']\n",
    "  om_df.set_index('date')\n",
    "\n",
    "for ms_df in ms_dfs:\n",
    "  ms_df.set_index('date')\n",
    "\n",
    "# print(vc_dfs[0].head())\n",
    "# print(type(vc_dfs[0]['date']))\n",
    "# print(om_dfs[0].head())\n",
    "# print(type(om_dfs[0]['date']))\n",
    "merged_dfs = []\n",
    "\n",
    "for i in range(len(vc_dfs)):\n",
    "  merged_df = pd.merge(vc_dfs[i], om_dfs[i])\n",
    "  merged_df = pd.merge(merged_df, ms_dfs[i]) \n",
    "  # , left_index=True, right_index=True)\n",
    "  merged_dfs.append(merged_df)\n",
    "\n",
    "print(merged_dfs[0].info())\n",
    "print(merged_dfs[0].head())\n",
    "\n",
    "# Merged_dfs is a single DF will all data points from different sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialising and De-serialising the final DFs for the historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the merged_df DataFrame to disk for later computations\n",
    "for i in range(len(cities)):\n",
    "  merged_dfs[i].to_pickle(\"./merged_df_\" + cities[i] + \".pkl\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded DFs for 4 cities.\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1447 entries, 0 to 1446\n",
      "Data columns (total 20 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   date     1447 non-null   object \n",
      " 1   tmax_vc  1447 non-null   float64\n",
      " 2   tmin_vc  1447 non-null   float64\n",
      " 3   humi_vc  1447 non-null   float64\n",
      " 4   wind_vc  1447 non-null   float64\n",
      " 5   tmax_om  1447 non-null   float64\n",
      " 6   tmin_om  1447 non-null   float64\n",
      " 7   sund_om  1447 non-null   float64\n",
      " 8   prec_om  1447 non-null   float64\n",
      " 9   wind_om  1447 non-null   float64\n",
      " 10  tavg_ms  1447 non-null   float64\n",
      " 11  tmin_ms  1447 non-null   float64\n",
      " 12  tmax_ms  1447 non-null   float64\n",
      " 13  prcp_ms  1159 non-null   float64\n",
      " 14  snow_ms  0 non-null      float64\n",
      " 15  wdir_ms  1159 non-null   float64\n",
      " 16  wspd_ms  1159 non-null   float64\n",
      " 17  wpgt_ms  0 non-null      float64\n",
      " 18  pres_ms  1159 non-null   float64\n",
      " 19  tsun_ms  0 non-null      float64\n",
      "dtypes: float64(19), object(1)\n",
      "memory usage: 226.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Unpickle the DataFrames\n",
    "city_history_dfs = []\n",
    "\n",
    "for i in range(len(cities)):\n",
    "  city_history_dfs.append(pd.read_pickle(\"./merged_df_\" + cities[i] + \".pkl\"))\n",
    "\n",
    "print(\"Loaded DFs for \" + str(len(city_history_dfs)) + \" cities.\\n\")\n",
    "print(city_history_dfs[0].info())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs542",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
