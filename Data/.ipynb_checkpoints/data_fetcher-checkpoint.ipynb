{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openmeteo-requests\n",
    "# !python -m pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This import doesn't even work on colab for some reason. Weird.\n",
    "# import openmeteo_requests\n",
    "\n",
    "# import requests_cache\n",
    "# import pandas as pd\n",
    "# from retry_requests import retry\n",
    "\n",
    "# # Setup the Open-Meteo API client with cache and retry on error\n",
    "# cache_session = requests_cache.CachedSession('.cache', expire_after = -1)\n",
    "# retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
    "# openmeteo = openmeteo_requests.Client(session = retry_session)\n",
    "\n",
    "# # Make sure all required weather variables are listed here\n",
    "# # The order of variables in hourly or daily is important to assign them correctly below\n",
    "# url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "# params = {\n",
    "# \t\"latitude\": [40.79736, 41.78701, 30.1444, 25.7738],\n",
    "# \t\"longitude\": [-73.97785, -87.77166, -97.66876, -80.1936],\n",
    "# \t\"start_date\": \"2024-03-01\",\n",
    "# \t\"end_date\": \"2023-03-01\",\n",
    "# \t\"hourly\": \"temperature_2m\"\n",
    "# }\n",
    "# responses = openmeteo.weather_api(url, params=params)\n",
    "\n",
    "# # Process first location. Add a for-loop for multiple locations or weather models\n",
    "# response = responses[0]\n",
    "# print(f\"Coordinates {response.Latitude()}°N {response.Longitude()}°E\")\n",
    "# print(f\"Elevation {response.Elevation()} m asl\")\n",
    "# print(f\"Timezone {response.Timezone()} {response.TimezoneAbbreviation()}\")\n",
    "# print(f\"Timezone difference to GMT+0 {response.UtcOffsetSeconds()} s\")\n",
    "\n",
    "# # Process hourly data. The order of variables needs to be the same as requested.\n",
    "# hourly = response.Hourly()\n",
    "# hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()\n",
    "\n",
    "# hourly_data = {\"date\": pd.date_range(\n",
    "# \tstart = pd.to_datetime(hourly.Time(), unit = \"s\", utc = True),\n",
    "# \tend = pd.to_datetime(hourly.TimeEnd(), unit = \"s\", utc = True),\n",
    "# \tfreq = pd.Timedelta(seconds = hourly.Interval()),\n",
    "# \tinclusive = \"left\"\n",
    "# )}\n",
    "# hourly_data[\"temperature_2m\"] = hourly_temperature_2m\n",
    "\n",
    "# hourly_dataframe = pd.DataFrame(data = hourly_data)\n",
    "# print(hourly_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pranav/miniconda3/bin/python\n",
      "3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:38:07) [Clang 16.0.6 ]\n",
      "sys.version_info(major=3, minor=11, micro=7, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API call using requests\n",
    "\n",
    "import requests\n",
    "\n",
    "latitudes = '25.7738,30.1444,41.78701,40.79736'\n",
    "longitudes = '-80.1936,-97.66876,-87.77166,-73.97785'\n",
    "start_date = '2016-01-01'\n",
    "end_date = '2024-03-01'\n",
    "\n",
    "# TODO: update this API call to include more features\n",
    "# sunshine_duration, \n",
    "required_metrics = \"temperature_2m_max,sunshine_duration,precipitation_probability_max\"\n",
    "url = \"https://api.open-meteo.com/v1/forecast?latitude=\"+ latitudes + \"&longitude=\" + longitudes+ \"&daily=\" + required_metrics + \"&start_date=\"+ start_date + \"&end_date=\" + end_date\n",
    "\n",
    "payload={}\n",
    "headers = {}\n",
    "\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "\n",
    "# print(response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = response.json()\n",
    "\n",
    "# 25.77380,-80.19360 - Miama, FL\n",
    "# 30.14440,-97.66876 - Texas\n",
    "# 41.78701,-87.77166 - Chicago, IL\n",
    "# 40.79736,-73.97785 - New York\n",
    "\n",
    "# Create individual vars for temps for each place\n",
    "temps_fl = data[0]\n",
    "temps_tx = data[1]\n",
    "temps_il = data[2]\n",
    "temps_ny = data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframes out of the dict\n",
    "def clean_temp_data(temps_data):\n",
    "    clean_fl = {\n",
    "        'time': [],\n",
    "        'temperature_2m_max': [],\n",
    "        'sunshine_duration':[],\n",
    "        'precipitation_probability_max':[]\n",
    "    }\n",
    "    for i in range(len(temps_data['daily']['time'])):\n",
    "        # print(temps_data['daily']['temperature_2m_max'][i])\n",
    "        if temps_data['daily']['temperature_2m_max'][i] is not None :\n",
    "            clean_fl['time'].append(temps_data['daily']['time'][i])\n",
    "            clean_fl['temperature_2m_max'].append(temps_data['daily']['temperature_2m_max'][i])\n",
    "            clean_fl['sunshine_duration'].append(temps_data['daily']['sunshine_duration'][i])\n",
    "            clean_fl['precipitation_probability_max'].append(temps_data['daily']['precipitation_probability_max'][i])\n",
    "            # print(temps_data['daily']['precipitation_probability_max'][i])\n",
    "            # print(temps_data['daily']['time'][i], temps_data['daily']['temperature_2m_max'][i])\n",
    "\n",
    "    # print(clean_fl)\n",
    "    \n",
    "    # Convert the dictionary to a DataFrame\n",
    "    clean_df = pd.DataFrame(clean_fl)\n",
    "    clean_df['sunshine_duration'].fillna(clean_df['sunshine_duration'].mean())\n",
    "    clean_df = clean_df.interpolate()\n",
    "    # print(clean_df)\n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           time  temperature_2m_max  sunshine_duration  \\\n",
      "0    2023-09-21                30.5           41110.61   \n",
      "1    2023-09-22                29.8           38020.24   \n",
      "2    2023-09-23                28.8           40928.12   \n",
      "3    2023-09-24                30.0           40744.77   \n",
      "4    2023-09-25                31.0           40016.88   \n",
      "..          ...                 ...                ...   \n",
      "158  2024-02-26                24.0           35295.91   \n",
      "159  2024-02-27                24.9           38988.08   \n",
      "160  2024-02-28                25.8           37944.30   \n",
      "161  2024-02-29                26.0           24794.83   \n",
      "162  2024-03-01                24.8           35646.97   \n",
      "\n",
      "     precipitation_probability_max  \n",
      "0                              NaN  \n",
      "1                              NaN  \n",
      "2                              NaN  \n",
      "3                              NaN  \n",
      "4                              NaN  \n",
      "..                             ...  \n",
      "158                            0.0  \n",
      "159                            0.0  \n",
      "160                            0.0  \n",
      "161                            6.0  \n",
      "162                           58.0  \n",
      "\n",
      "[163 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b9/fkf035lj1y786gv5xh300_qc0000gn/T/ipykernel_14378/2309240598.py:24: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  clean_df = clean_df.interpolate()\n",
      "/var/folders/b9/fkf035lj1y786gv5xh300_qc0000gn/T/ipykernel_14378/2309240598.py:24: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  clean_df = clean_df.interpolate()\n",
      "/var/folders/b9/fkf035lj1y786gv5xh300_qc0000gn/T/ipykernel_14378/2309240598.py:24: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  clean_df = clean_df.interpolate()\n",
      "/var/folders/b9/fkf035lj1y786gv5xh300_qc0000gn/T/ipykernel_14378/2309240598.py:24: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  clean_df = clean_df.interpolate()\n"
     ]
    }
   ],
   "source": [
    "df_fl = clean_temp_data(temps_fl)\n",
    "df_il = clean_temp_data(temps_il)\n",
    "df_tx = clean_temp_data(temps_tx)\n",
    "df_ny = clean_temp_data(temps_ny)\n",
    "\n",
    "print(df_fl)\n",
    "# print(df_il)\n",
    "# print(df_tx)\n",
    "# print(df_ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some time related cleanup\n",
    "\n",
    "df = df_fl\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "# Calculate the number of days since the first date in the dataset\n",
    "min_date = df['time'].min()\n",
    "df['time_delta'] = (df['time'] - min_date).dt.days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 2.9424044871474737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranav/miniconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 1 features, but LinearRegression is expecting 2 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m predict_precipitation_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m45\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Use the model to predict\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m predict_temp \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpredict_date_delta\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted temperature for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredict_date\u001b[38;5;241m.\u001b[39mdate()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredict_temp[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m°\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/linear_model/_base.py:286\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    273\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/linear_model/_base.py:269\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    267\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 269\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 1 features, but LinearRegression is expecting 2 features as input."
     ]
    }
   ],
   "source": [
    "# Define features and target variable\n",
    "X = df[['time_delta', 'sunshine_duration']]  # Our features\n",
    "y = df['temperature_2m_max']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f\"Test MSE: {mse}\")\n",
    "\n",
    "\n",
    "# Plotting the actual vs predicted values\n",
    "plt.figure(figsize=(10, 6))  # Set the figure size for better readability\n",
    "plt.scatter(y_test, predictions, alpha=0.5)  # Plot the predictions vs the actual values\n",
    "\n",
    "# Plot a line representing the perfect predictions\n",
    "# This means every actual value is equal to the predicted value\n",
    "min_val = min(y_test.min(), predictions.min())\n",
    "max_val = max(y_test.max(), predictions.max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--', lw=2)\n",
    "\n",
    "plt.title('Actual vs. Predicted Temperatures')\n",
    "plt.xlabel('Actual Temperature (2m Max)')\n",
    "plt.ylabel('Predicted Temperature')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# To predict the temperature for a specific future date\n",
    "predict_date = pd.to_datetime('2024-03-02')  # Example date\n",
    "predict_date_delta = (predict_date - min_date).days # Convert to numerical format\n",
    "predict_sunlight_duration = 34275\n",
    "predict_precipitation_max = 45\n",
    "\n",
    "# Use the model to predict\n",
    "predict_temp = model.predict([[predict_date_delta]])\n",
    "print(f\"Predicted temperature for {predict_date.date()}: {predict_temp[0]}°\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
