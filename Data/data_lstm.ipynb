{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some constants\n",
    "latitude = [40.79736, 41.78701, 30.1444, 25.7738]\n",
    "longitude = [-73.97785, -87.77166, -97.66876, -80.1936]\n",
    "cities = [\"ny\", \"il\", \"tx\", \"fl\"]\n",
    "start_date = \"2016-01-01\"\n",
    "end_date = \"2024-03-20\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrediction(city):\n",
    "    model = tf.keras.models.load_model('model_'+city+'.keras')\n",
    "    df = pd.read_pickle(\"./data_cleaned_\"+ city +\".pkl\")\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df.set_index('date', inplace=True)\n",
    "    df = df.rename(columns={\"day\": \"day_of_year\", \"tmax_avg\":\"tmax\", \"tmin_avg\": \"tmin\", 'prec_om': \"prec\", 'humi_vc': \"humi\"})\n",
    "    # df.info()\n",
    "    features = ['day_of_year', 'tmax', 'tmin', 'prec', 'humi']\n",
    "    df = df[features]\n",
    "    target = 'tmax'\n",
    "\n",
    "    # Normalize the features\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = scaler.fit_transform(df[features])\n",
    "\n",
    "    time_steps = 60  # Use this many days of data to predict the next day's 'tmax'\n",
    "    # X, y = create_dataset(df_scaled, df_scaled[:, 1], time_steps)\n",
    "    # split = int(len(X) * 0.75)  # 70% for training\n",
    "\n",
    "    # # Split the data\n",
    "    # X_train, X_test = X[:split], X[split:]\n",
    "    # y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "    last_days_data = np.array(df[-(time_steps-1):])\n",
    "\n",
    "    last_days_scaled = scaler.transform(last_days_data)\n",
    "    last_days_scaled = np.expand_dims(last_days_scaled, axis=0)\n",
    "    predicted_tmax_scaled = model.predict(last_days_scaled)\n",
    "    dummy_array = np.zeros((1, len(features))) \n",
    "    dummy_array[:, 1] = predicted_tmax_scaled\n",
    "    inverse_transformed_array = scaler.inverse_transform(dummy_array)\n",
    "    predicted_tmax = inverse_transformed_array[:, 1]\n",
    "\n",
    "    print(f\"Predicted 'tmax' for {city} for next day: {predicted_tmax[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in cities:\n",
    "  getPrediction(city)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs542",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
